name: mammal_solubility_finetune
root: "."
model_dir: ${root}/${name}
seed: 1234

task:
  _target_: mammal.examples.protein_solubility.task.ProteinSolubilityTask
  _partial_: True
  # details about the arguments below can be found on mammal.examples.protein_solubility.task.ProteinSolubilityTask()
  name: solubility_prediction
  seed: ${seed}
  data_module_kwargs:
    # details about the arguments below can be found on mammal.examples.protein_solubility.pl_data_module.ProteinSolubilityDataModule()
    data_path: ./example_solubility_data

    train_dl_kwargs: # Dataloader constructor parameters
      num_workers: 8
    valid_dl_kwargs: # Dataloader constructor parameters
      num_workers: 8

    batch_size: 6
    protein_max_seq_length: 1250
    encoder_input_max_seq_len: 1260
    labels_max_seq_len: 4

# tokenizer
tokenizer:
  tokenizer_path: ibm/biomed.omics.bl.sm.ma-ted-458m

model:
  mammal_kwargs: null # arguments for Mammal.__init__()
  pretrained_kwargs: # arguments for Mammal.from_pretrained() which triggered only if pretrained_model_name_or_path is not None
    pretrained_model_name_or_path: ibm/biomed.omics.bl.sm.ma-ted-458m

# lightning module
module:
  opt_callable:
    _target_: torch.optim.AdamW
    _partial_: true
    # arguments for torch.optim.AdamW()
    lr: 0.00001

  lr_sch_callable:
    _target_: mammal.lr_schedulers.cosine_annealing_with_warmup_lr_scheduler
    _partial_: True
    # arguments for mammal.lr_schedulers.cosine_annealing_with_warmup_lr_scheduler()
    T_max: 20000
    eta_min_factor: 0.1

  model_dir: ${model_dir}
  best_epoch_source:
    # arguments for pytorch_lightning.callbacks.ModelCheckpoint()
    monitor: validation.metrics.solubility_prediction_acc  # possible options are validation.metrics.<task_name>_<metric_name>

    mode: max

# train
trainer:
  # arguments for pytorch_lightning.Trainer()
  max_epochs: 1000
  default_root_dir: ${model_dir}
  accelerator: "auto"
  devices: 1
  num_nodes: 1
  strategy: "ddp_find_unused_parameters_true"
  use_distributed_sampler: False  # Must be set when using a batch sampler
  num_sanity_val_steps: 0
  # limit_train_batches: 128
  # limit_val_batches: 128

# experiment tracker
track_clearml: # arguments for fuse.dl.lightning.pl_funcs.start_clearml_logger
  project_name: "mammal/opensource"
  task_name: ${name}
  tags: "mammal"
  reuse_last_task_id: True
  continue_last_task: False
  offline_mode: False

evaluate : false #if true then it will use lightning's validate on the test dataloader

hydra:
  run:
    dir: ${model_dir}
  job:
    chdir: False
