Metadata-Version: 2.1
Name: rlmodule
Version: 0.1.6.3
Summary: Flexible reinforcement learning models instantiators library
Author: Lopatovsky
Author-email: lopatovsky@gmail.com
Maintainer: Lopatovsky
License: MIT License
Project-URL: Homepage, https://github.com/FabricaAI/rlmodule
Project-URL: Documentation, https://github.com/FabricaAI/rlmodule
Project-URL: Discussions, https://github.com/FabricaAI/rlmodule/discussions
Project-URL: Bug Reports, https://github.com/FabricaAI/rlmodule/issues
Project-URL: Say Thanks!, https://github.com/lopatovsky
Project-URL: Source, https://github.com/FabricaAI/rlmodule
Keywords: reinforcement-learning,machine-learning,reinforcement,machine,learning,rl,rl-models,rl-modules,models,modules
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: gym
Requires-Dist: gymnasium ==0.29.0
Requires-Dist: torch >=1.9
Requires-Dist: skrl >=1.3.0
Provides-Extra: all
Requires-Dist: skrl >=1.3.0 ; extra == 'all'
Provides-Extra: skrl
Requires-Dist: skrl >=1.3.0 ; extra == 'skrl'

# rlmodule
Flexible reinforcement learning models instantiators library

Function approximators simple, but still strong. RNN - GRU - LSTM / SAC

Now it only supports skrl, but is intended to be library agnostic - in later expansion

try other algos
shared separate model


<!--
# todo
# some envs have by default range on which they work, like pendulum -2, 2, need to propaget that in.
# cnn
# WRITE README tutorial
# Run & fix pre-commit
# annotate cfgs in modules - why doesn't work TYPE_CHECKING
# extensive comments
# Launch new version to pip
# Import new version in Isaac-lab
# lazy linear? what is it ?
# random model run add function back
-->


## How to run

### Install rlmodule from local code

- Make sure you are in base rlmodule dict.

- Start virtual env.
```
python3 -m venv venv
source venv/bin/activate
```
- Install library from local code
```
pip install -e .
```
Note: sometimes installation may fail, if there is a run/ dir present, you may need to remove it (TODO: fix)
```
rm -rf runs
```

### Run chosen example
```
python3 rlmodule/skrl/torch/examples/gymnasium/pendulum_ppo_mlp_separate_model.py
```

Optional: observe run results in Tensorboard

```
tensorboard --logdir=runs/
```



## Update new version to PIP

Change version name in pyproject.toml

```
pip install build twine
```

```
rm -rf runs
python -m build
```

```
twine upload dist/*
```
