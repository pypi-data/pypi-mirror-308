##################################################################################
#                       Auto-generated Metaflow stub file                        #
# MF version: 2.12.27.1+obcheckpoint(0.1.2);ob(v1)                               #
# Generated on 2024-11-13T19:05:29.433231                                        #
##################################################################################

from __future__ import annotations

import typing
if typing.TYPE_CHECKING:
    import metaflow.exception

class MetaflowException(Exception, metaclass=type):
    def __init__(self, msg = "", lineno = None):
        ...
    def __str__(self):
        ...
    ...

EVENTS_SFN_ACCESS_IAM_ROLE: None

S3_ENDPOINT_URL: None

SFN_DYNAMO_DB_TABLE: None

SFN_EXECUTION_LOG_GROUP_ARN: None

SFN_IAM_ROLE: None

SFN_S3_DISTRIBUTED_MAP_OUTPUT_PATH: None

def deploy_time_eval(value):
    ...

class Batch(object, metaclass=type):
    def __init__(self, metadata, environment):
        ...
    def list_jobs(self, flow_name, run_id, user, echo):
        ...
    def kill_jobs(self, flow_name, run_id, user, echo):
        ...
    def create_job(self, step_name, step_cli, task_spec, code_package_sha, code_package_url, code_package_ds, image, queue, iam_role = None, execution_role = None, cpu = None, gpu = None, memory = None, run_time_limit = None, shared_memory = None, max_swap = None, swappiness = None, inferentia = None, efa = None, env = {}, attrs = {}, host_volumes = None, efs_volumes = None, use_tmpfs = None, tmpfs_tempdir = None, tmpfs_size = None, tmpfs_path = None, num_parallel = 0, ephemeral_storage = None, log_driver = None, log_options = None):
        ...
    def launch_job(self, step_name, step_cli, task_spec, code_package_sha, code_package_url, code_package_ds, image, queue, iam_role = None, execution_role = None, cpu = None, gpu = None, memory = None, run_time_limit = None, shared_memory = None, max_swap = None, swappiness = None, inferentia = None, efa = None, host_volumes = None, efs_volumes = None, use_tmpfs = None, tmpfs_tempdir = None, tmpfs_size = None, tmpfs_path = None, num_parallel = 0, env = {}, attrs = {}, ephemeral_storage = None, log_driver = None, log_options = None):
        ...
    def wait(self, stdout_location, stderr_location, echo = None):
        ...
    ...

class EventBridgeClient(object, metaclass=type):
    def __init__(self, name):
        ...
    def cron(self, cron):
        ...
    def role_arn(self, role_arn):
        ...
    def state_machine_arn(self, state_machine_arn):
        ...
    def schedule(self):
        ...
    def delete(self):
        ...
    ...

class StepFunctionsClient(object, metaclass=type):
    def __init__(self):
        ...
    def search(self, name):
        ...
    def push(self, name, definition, role_arn, log_execution_history):
        ...
    def get(self, name):
        ...
    def trigger(self, state_machine_arn, input):
        ...
    def list_executions(self, state_machine_arn, states):
        ...
    def terminate_execution(self, execution_arn):
        ...
    def get_state_machine_arn(self, name):
        ...
    def delete(self, name):
        ...
    ...

class StepFunctionsException(metaflow.exception.MetaflowException, metaclass=type):
    ...

class StepFunctionsSchedulingException(metaflow.exception.MetaflowException, metaclass=type):
    ...

class StepFunctions(object, metaclass=type):
    def __init__(self, name, graph, flow, code_package_sha, code_package_url, production_token, metadata, flow_datastore, environment, event_logger, monitor, tags = None, namespace = None, username = None, max_workers = None, workflow_timeout = None, is_project = False, use_distributed_map = False):
        ...
    def to_json(self):
        ...
    def trigger_explanation(self):
        ...
    def deploy(self, log_execution_history):
        ...
    def schedule(self):
        ...
    @classmethod
    def delete(cls, name):
        ...
    @classmethod
    def terminate(cls, flow_name, name):
        ...
    @classmethod
    def trigger(cls, name, parameters):
        ...
    @classmethod
    def list(cls, name, states):
        ...
    @classmethod
    def get_existing_deployment(cls, name):
        ...
    @classmethod
    def get_execution(cls, state_machine_name, name):
        ...
    ...

class Workflow(object, metaclass=type):
    def __init__(self, name):
        ...
    def mode(self, mode):
        ...
    def start_at(self, start_at):
        ...
    def add_state(self, state):
        ...
    def timeout_seconds(self, timeout_seconds):
        ...
    def to_json(self, pretty = False):
        ...
    ...

class State(object, metaclass=type):
    def __init__(self, name):
        ...
    def resource(self, resource):
        ...
    def next(self, state):
        ...
    def end(self):
        ...
    def parameter(self, name, value):
        ...
    def output_path(self, output_path):
        ...
    def result_path(self, result_path):
        ...
    def result_selector(self, name, value):
        ...
    def retry_strategy(self, retry_strategy):
        ...
    def batch(self, job):
        ...
    def dynamo_db(self, table_name, primary_key, values):
        ...
    ...

class Pass(object, metaclass=type):
    def __init__(self, name):
        ...
    def end(self):
        ...
    def parameter(self, name, value):
        ...
    def output_path(self, output_path):
        ...
    ...

class Parallel(object, metaclass=type):
    def __init__(self, name):
        ...
    def branch(self, workflow):
        ...
    def next(self, state):
        ...
    def output_path(self, output_path):
        ...
    def result_path(self, result_path):
        ...
    ...

class Map(object, metaclass=type):
    def __init__(self, name):
        ...
    def iterator(self, workflow):
        ...
    def next(self, state):
        ...
    def items_path(self, items_path):
        ...
    def parameter(self, name, value):
        ...
    def max_concurrency(self, max_concurrency):
        ...
    def output_path(self, output_path):
        ...
    def result_path(self, result_path):
        ...
    def item_reader(self, item_reader):
        ...
    def result_writer(self, bucket, prefix):
        ...
    ...

class JSONItemReader(object, metaclass=type):
    def __init__(self):
        ...
    def resource(self, resource):
        ...
    def parameter(self, name, value):
        ...
    def output_path(self, output_path):
        ...
    ...

