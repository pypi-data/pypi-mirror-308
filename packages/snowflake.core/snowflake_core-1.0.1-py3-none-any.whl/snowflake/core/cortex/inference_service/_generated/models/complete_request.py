# coding: utf-8
"""
    Cortex Inference API.

    OpenAPI 3.0 specification for the Cortex REST API  # noqa: E501

    The version of the OpenAPI document: 0.1.0
    Contact: support@snowflake.com
    Generated by: https://openapi-generator.tech

    Do not edit this file manually.
"""

from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from typing import Union

from snowflake.core.cortex.inference_service._generated.models.complete_request_messages_inner import CompleteRequestMessagesInner

from snowflake.core.cortex.inference_service._generated.models.guardrails_config import GuardrailsConfig

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr

from typing import Any, ClassVar, Dict, List, Optional, Union

from typing_extensions import Annotated


class CompleteRequest(BaseModel):
    """A model object representing the CompleteRequest resource.

    Constructs an object of type CompleteRequest with the provided properties.

    Parameters
    __________
    model : str
        The model name. See documentation for possible values.
    messages : List[CompleteRequestMessagesInner]

    temperature : float,  default 0
        Temperature controls the amount of randomness used in response generation. A higher temperature corresponds to more randomness.
    top_p : float,  default 1.0
        Threshold probability for nucleus sampling. A higher top-p value increases the diversity of tokens that the model considers, while a lower value results in more predictable output.
    max_tokens : int,  default 4096
        The maximum number of output tokens to produce. The default value is model-dependent.
    max_output_tokens : int, optional
        Deprecated in favor of "max_tokens", which has identical behavior.
    guardrails : GuardrailsConfig, optional
    """

    model: StrictStr

    messages: Annotated[List[CompleteRequestMessagesInner],
                        Field(min_length=1)]

    temperature: Optional[Union[Annotated[float,
                                          Field(strict=True, ge=0.0)],
                                Annotated[int, Field(strict=True, ge=0)]]] = 0

    top_p: Optional[Union[Annotated[float,
                                    Field(le=1.0, strict=True, ge=0.0)],
                          Annotated[int,
                                    Field(le=1, strict=True, ge=0)]]] = 1.0

    max_tokens: Optional[Annotated[int, Field(strict=True, ge=0)]] = 4096

    max_output_tokens: Optional[StrictInt] = None

    guardrails: Optional[GuardrailsConfig] = None

    __properties = [
        "model", "messages", "temperature", "top_p", "max_tokens",
        "max_output_tokens", "guardrails"
    ]

    class Config:
        populate_by_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias."""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias."""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> CompleteRequest:
        """Create an instance of CompleteRequest from a JSON string."""
        return cls.from_dict(json.loads(json_str))

    def to_dict(
        self,
        hide_readonly_properties: bool = False,
    ) -> Dict[str, Any]:
        """Returns the dictionary representation of the model using alias."""

        exclude_properties = set()

        if hide_readonly_properties:
            exclude_properties.update({})

        _dict = dict(
            self._iter(to_dict=True,
                       by_alias=True,
                       exclude=exclude_properties,
                       exclude_none=True))

        # override the default output from pydantic by calling `to_dict()` of each item in messages (list)
        _items = []
        if self.messages:
            for _item in self.messages:
                if _item:
                    _items.append(_item.to_dict())
            _dict['messages'] = _items

        # override the default output from pydantic by calling `to_dict()` of guardrails
        if self.guardrails:
            _dict['guardrails'] = self.guardrails.to_dict()

        # set to None if max_output_tokens (nullable) is None
        if self.max_output_tokens is None:
            _dict['max_output_tokens'] = None

        # set to None if guardrails (nullable) is None
        if self.guardrails is None:
            _dict['guardrails'] = None

        return _dict

    def to_dict_without_readonly_properties(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model without readonly properties."""
        return self.to_dict(hide_readonly_properties=True)

    @classmethod
    def from_dict(cls, obj: dict) -> CompleteRequest:
        """Create an instance of CompleteRequest from a dict."""

        if obj is None:
            return None

        if type(obj) is not dict:
            return CompleteRequest.parse_obj(obj)

        _obj = CompleteRequest.parse_obj({
            "model":
            obj.get("model"),
            "messages": [
                CompleteRequestMessagesInner.from_dict(_item)
                for _item in obj.get("messages")
            ] if obj.get("messages") is not None else None,
            "temperature":
            obj.get("temperature")
            if obj.get("temperature") is not None else 0,
            "top_p":
            obj.get("top_p") if obj.get("top_p") is not None else 1.0,
            "max_tokens":
            obj.get("max_tokens")
            if obj.get("max_tokens") is not None else 4096,
            "max_output_tokens":
            obj.get("max_output_tokens"),
            "guardrails":
            GuardrailsConfig.from_dict(obj.get("guardrails"))
            if obj.get("guardrails") is not None else None,
        })

        return _obj


from typing import Optional, List, Dict

from snowflake.core.cortex.inference_service._generated.models.complete_request_messages_inner import CompleteRequestMessagesInner

from snowflake.core.cortex.inference_service._generated.models.guardrails_config import GuardrailsConfig


class CompleteRequestModel():

    def __init__(
        self,
        model: str,
        messages: List[CompleteRequestMessagesInner],
        # optional properties
        temperature: Optional[float] = 0,
        top_p: Optional[float] = 1.0,
        max_tokens: Optional[int] = 4096,
        max_output_tokens: Optional[int] = None,
        guardrails: Optional[GuardrailsConfig] = None,
    ):
        """A model object representing the CompleteRequest resource.

        Constructs an object of type CompleteRequest with the provided properties.

        Parameters
        __________
        model : str
            The model name. See documentation for possible values.
        messages : List[CompleteRequestMessagesInner]

        temperature : float,  default 0
            Temperature controls the amount of randomness used in response generation. A higher temperature corresponds to more randomness.
        top_p : float,  default 1.0
            Threshold probability for nucleus sampling. A higher top-p value increases the diversity of tokens that the model considers, while a lower value results in more predictable output.
        max_tokens : int,  default 4096
            The maximum number of output tokens to produce. The default value is model-dependent.
        max_output_tokens : int, optional
            Deprecated in favor of "max_tokens", which has identical behavior.
        guardrails : GuardrailsConfig, optional
        """

        self.model = model
        self.messages = messages
        self.temperature = temperature
        self.top_p = top_p
        self.max_tokens = max_tokens
        self.max_output_tokens = max_output_tokens
        self.guardrails = guardrails

    __properties = [
        "model", "messages", "temperature", "top_p", "max_tokens",
        "max_output_tokens", "guardrails"
    ]

    def _to_model(self):
        return CompleteRequest(
            model=self.model,
            messages=[x._to_model() for x in self.messages]
            if self.messages is not None else None,
            temperature=self.temperature,
            top_p=self.top_p,
            max_tokens=self.max_tokens,
            max_output_tokens=self.max_output_tokens,
            guardrails=self.guardrails._to_model()
            if self.guardrails is not None else None,
        )

    @classmethod
    def _from_model(cls, model) -> CompleteRequestModel:
        return CompleteRequestModel(
            model=model.model,
            messages=[
                CompleteRequestMessagesInnerModel._from_model(x)
                for x in model.messages
            ] if model.messages is not None else None,
            temperature=model.temperature,
            top_p=model.top_p,
            max_tokens=model.max_tokens,
            max_output_tokens=model.max_output_tokens,
            guardrails=GuardrailsConfigModel._from_model(model.guardrails)
            if model.guardrails is not None else None,
        )

    def to_dict(self):
        """Creates a dictionary of the properties from a CompleteRequest.

        This method constructs a dictionary with the key-value entries corresponding to the properties of the CompleteRequest object.

        Returns
        _______
        dict
            A dictionary object created using the input model.
        """
        return self._to_model().to_dict()

    @classmethod
    def from_dict(cls, obj: dict) -> CompleteRequestModel:
        """Creates an instance of CompleteRequest from a dict.

        This method constructs a CompleteRequest object from a dictionary with the key-value pairs of its properties.

        Parameters
        ----------
        obj : dict
            A dictionary whose keys and values correspond to the properties of the resource object.

        Returns
        _______
        CompleteRequest
            A CompleteRequest object created using the input dictionary; this will fail if the required properties are missing.
        """
        return cls._from_model(CompleteRequest.from_dict(obj))


CompleteRequest._model_class = CompleteRequestModel
