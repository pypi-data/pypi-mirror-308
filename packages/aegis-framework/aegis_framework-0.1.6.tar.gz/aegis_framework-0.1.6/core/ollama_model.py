import subprocess

class OllamaLocalModel:
    """
    Class to interface with a local Ollama model using CLI commands.
    """

    def __init__(self, model=None):
        """
        Initialize the Ollama model interface.

        Args:
            model (str, optional): The model name or version to use. If None, it prompts the user for input.
        """
        self.model = model if model else self.get_user_model_choice()

    def get_user_model_choice(self):
        """
        Prompt the user to enter the model name if not specified during initialization.

        Returns:
            str: The model name entered by the user.
        """
        model_choice = input("Please enter the name of the Ollama model to use (e.g., 'gemma2:9b'): ")
        return model_choice

    def invoke(self, prompt):
        """
        Generate a response from the Ollama model using the CLI.

        Args:
            prompt (str): The input prompt for the model.

        Returns:
            str: The output generated by the model, or an error message if execution fails.
        """
        try:
            # Limit prompt length to prevent overloading the CLI command
            if len(prompt) > 10000:
                return "Error: Prompt too long for invocation."

            result = subprocess.run(
                ["ollama", "run", self.model],
                input=prompt,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            return f"Error: {e.stderr}"
        except Exception as e:
            return f"Unexpected error: {e}"
