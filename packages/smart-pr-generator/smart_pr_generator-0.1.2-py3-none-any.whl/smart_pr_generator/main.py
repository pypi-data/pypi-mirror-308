import argparse
import logging
import os

import requests
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_openai import ChatOpenAI
from packaging import version

from smart_pr_generator.config import Config
from smart_pr_generator.helpers import get_git_info
from smart_pr_generator.helpers.github_client import GitHubClient
from smart_pr_generator.tools import fetch_jira_issue

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

VERSION = "0.1.2"


def check_package_updates():
    """í˜„ì¬ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì™€ PyPIì˜ ìµœì‹  ë²„ì „ì„ ë¹„êµ"""
    try:
        # PyPI API í˜¸ì¶œ
        response = requests.get("https://pypi.org/pypi/smart-pr-generator/json")
        if response.status_code == 200:
            latest_version = response.json()["info"]["version"]

            # ë²„ì „ ë¹„êµ
            update_available = version.parse(latest_version) > version.parse(VERSION)

        # ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ ì¶œë ¥
        if update_available:
            print("-" * 60)
            print("ğŸ“¦ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
            print(f"í˜„ì¬ ë²„ì „: {VERSION}")
            print(f"ìµœì‹  ë²„ì „: {latest_version}")
            print("\nì—…ë°ì´íŠ¸ ëª…ë ¹ì–´: pip install --upgrade smart-pr-generator")
            print("-" * 60)
            print("")
    except Exception:
        pass


# main() í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--version",
        action="version",
        version=f"v{VERSION}",
        help="í˜„ì¬ ë²„ì „ì„ ì¶œë ¥í•©ë‹ˆë‹¤",
    )
    parser.add_argument(
        "--no-verify",
        action="store_true",
        help="ì»¤ë°‹ë˜ì§€ ì•Šì€ ë³€ê²½ì‚¬í•­ ì²´í¬ë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤",
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="GitHub PR ìƒì„± ë‹¨ê³„ë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤",
    )
    args = parser.parse_args()

    check_package_updates()

    Config().load_env_files()

    print("ğŸš€ PR ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    commits, branch, owner, repo, default_branch = get_git_info(
        no_verify=args.no_verify
    )
    print(f"commits: {len(commits)}, branch: {branch}, owner: {owner}, repo: {repo}")

    print("ğŸ¤– AIë¡œ PR ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” ì¤‘...")
    try:
        llm = ChatOpenAI(
            model="gpt-4o",
            api_key=os.environ["LAAS_API_KEY"],
            base_url="https://api-laas.wanted.co.kr/api/preset/v2/",
            default_headers={
                "apiKey": os.environ["LAAS_API_KEY"],
                "Content-Type": "application/json",
                "project": "SMART_PR_GENERATOR",
            },
            extra_body={
                "hash": "e86358af60cf8366835060943349c2ab1954950253ab35d36abd2e7089d5f39a",
            },
        )

        messages = [
            ("user", f"# Branch:\n {branch}\n\n# Commits:\n" + "\n".join(commits))
        ]

        answer: AIMessage = llm.invoke(messages)

        if answer.response_metadata["finish_reason"] == "tool_calls":
            # print("ë„êµ¬ í˜¸ì¶œ")
            for tool_call in answer.tool_calls:
                # tool ì •ë³´ ì¶”ì¶œ
                # print("tool_call", tool_call)
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                # print("tool_args", tool_args)

                # tool ì‹¤í–‰
                if tool_name == "fetch_jira_issue":
                    tool_result = fetch_jira_issue.invoke(tool_args)
                else:
                    raise ValueError(f"Unknown tool: {tool_name}")

                # tool ì‹¤í–‰ ê²°ê³¼ë¥¼ OpenAIì— ì „ë‹¬
                messages.extend(
                    [
                        answer,
                        {
                            "role": "tool",
                            "name": tool_name,
                            "content": str(tool_result),
                            "tool_call_id": tool_call["id"],
                        },
                    ]
                )

                answer: AIMessage = llm.invoke(messages)

        print("âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        pr_data = JsonOutputParser().invoke(answer)

        if args.test:
            print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: GitHub PR ìƒì„±ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤")
            return

        print("ğŸ“¨ GitHub PRì„ ìƒì„±í•˜ëŠ” ì¤‘...")
        print(f"https://api.github.com/repos/{owner}/{repo}/pulls")
        github_client = GitHubClient(os.environ["GITHUB_TOKEN"])
        pr_response = github_client.create_pull_request(
            owner=owner,
            repo=repo,
            title=pr_data["title"],
            body=pr_data["description"],
            head=branch,
            base=default_branch,
        )
        pr_url = pr_response["html_url"]
        print("âœ¨ PRì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ”— PR URL: {pr_url}")
    except Exception as e:
        print(f"âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ (ì—ëŸ¬: {e})")


if __name__ == "__main__":
    main()
