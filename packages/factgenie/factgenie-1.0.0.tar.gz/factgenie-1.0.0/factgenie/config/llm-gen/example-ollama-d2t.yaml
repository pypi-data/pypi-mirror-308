type: ollama_gen
model: llama3
# You can run ollama also on other machine than factgenie 
#  e.g. we run it on a machine tdll-3gpu3 and access it from any machine which is withing the same firewall
#  in that case we use api_url: http://tdll-3gpu3.ufal.hide.ms.mff.cuni.cz:11434/api/
# If you run ollama at the same machine as factgenie let's use just localhost.
api_url: http://localhost:11434/api/
model_args:
model_args:
  num_ctx: 8192
  num_predict: 1024
  seed: 42
  temperature: 1.0
  top_k: 50
  top_p: 0.9
system_msg: "You are an expert data-to-text system. You understand structured data and you can correctly operate with units and numerical values. You are designed to output plain text summaries from structured data input."
start_with: "Sure, here is the required output:\n\""
extra_args:
  remove_suffix: '"'
prompt_template: |
  Given the data:
  ```
  {data}
  ```
  Generate a summary in plain text, describing facts and values contained in the input:

  *Example:*
  data:
  ```
  Nokia 3310
  -----
  - **color**: black, blue, grey
  - **display**: 320x240px
  ```
  output (product description):
  ```
  Nokia 3310 features a 320x240 display. It is available in black, blue and grey color.
  ```
  Do not add or fabricate any detail not reflected in the data. Also do not be too strict: some facts can be less specific than in the data (rounded values, shortened or abbreviated text, etc.).
