"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from datetime import datetime
from enum import Enum
from orq_poc_python_client.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from pydantic import model_serializer
from typing import Any, AsyncGenerator, Generator, List, Optional, Union
from typing_extensions import NotRequired, TypedDict


class PostV2DeploymentsInvokeObject(str, Enum):
    r"""Indicates the type of model used to generate the response"""

    CHAT = "chat"
    COMPLETION = "completion"
    IMAGE = "image"


class PostV2DeploymentsInvokeProvider(str, Enum):
    r"""The provider used to generate the response"""

    COHERE = "cohere"
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    HUGGINGFACE = "huggingface"
    REPLICATE = "replicate"
    GOOGLE = "google"
    GOOGLE_AI = "google-ai"
    AZURE = "azure"
    AWS = "aws"
    ANYSCALE = "anyscale"
    PERPLEXITY = "perplexity"
    GROQ = "groq"
    FAL = "fal"
    LEONARDOAI = "leonardoai"
    NVIDIA = "nvidia"


class PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamRole(
    str, Enum
):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class PostV2DeploymentsInvokeMessage3TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamRole
    r"""The role of the prompt message"""
    url: str


class PostV2DeploymentsInvokeMessage3(BaseModel):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamRole
    r"""The role of the prompt message"""

    url: str


class PostV2DeploymentsInvokeMessageDeploymentsResponse200Role(str, Enum):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class PostV2DeploymentsInvokeMessageDeployments2TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200Role
    r"""The role of the prompt message"""
    content: Nullable[str]


class PostV2DeploymentsInvokeMessageDeployments2(BaseModel):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200Role
    r"""The role of the prompt message"""

    content: Nullable[str]

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamResponseBodyRole(
    str, Enum
):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class PostV2DeploymentsInvokeMessageDeploymentsType(str, Enum):
    FUNCTION = "function"


class PostV2DeploymentsInvokeMessageDeploymentsFunctionTypedDict(TypedDict):
    name: str
    arguments: str
    r"""JSON string arguments for the functions"""


class PostV2DeploymentsInvokeMessageDeploymentsFunction(BaseModel):
    name: str

    arguments: str
    r"""JSON string arguments for the functions"""


class PostV2DeploymentsInvokeMessageDeploymentsToolCallsTypedDict(TypedDict):
    type: PostV2DeploymentsInvokeMessageDeploymentsType
    function: PostV2DeploymentsInvokeMessageDeploymentsFunctionTypedDict
    id: NotRequired[str]
    index: NotRequired[float]


class PostV2DeploymentsInvokeMessageDeploymentsToolCalls(BaseModel):
    type: PostV2DeploymentsInvokeMessageDeploymentsType

    function: PostV2DeploymentsInvokeMessageDeploymentsFunction

    id: Optional[str] = None

    index: Optional[float] = None


class PostV2DeploymentsInvokeMessageDeployments1TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamResponseBodyRole
    r"""The role of the prompt message"""
    tool_calls: List[PostV2DeploymentsInvokeMessageDeploymentsToolCallsTypedDict]
    content: NotRequired[Nullable[str]]


class PostV2DeploymentsInvokeMessageDeployments1(BaseModel):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponse200TextEventStreamResponseBodyRole
    r"""The role of the prompt message"""

    tool_calls: List[PostV2DeploymentsInvokeMessageDeploymentsToolCalls]

    content: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["content"]
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


PostV2DeploymentsInvokeDeploymentsMessageTypedDict = Union[
    PostV2DeploymentsInvokeMessageDeployments2TypedDict,
    PostV2DeploymentsInvokeMessage3TypedDict,
    PostV2DeploymentsInvokeMessageDeployments1TypedDict,
]


PostV2DeploymentsInvokeDeploymentsMessage = Union[
    PostV2DeploymentsInvokeMessageDeployments2,
    PostV2DeploymentsInvokeMessage3,
    PostV2DeploymentsInvokeMessageDeployments1,
]


class PostV2DeploymentsInvokeDeploymentsChoicesTypedDict(TypedDict):
    index: float
    message: NotRequired[PostV2DeploymentsInvokeDeploymentsMessageTypedDict]
    finish_reason: NotRequired[Nullable[str]]


class PostV2DeploymentsInvokeDeploymentsChoices(BaseModel):
    index: float

    message: Optional[PostV2DeploymentsInvokeDeploymentsMessage] = None

    finish_reason: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["message", "finish_reason"]
        nullable_fields = ["finish_reason"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2DeploymentsInvokeMetadataTypedDict(TypedDict):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""
    page_number: Nullable[float]
    r"""Page number of the chunk"""
    file_type: str
    r"""Type of the file"""
    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""
    rerank_score: NotRequired[float]
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""


class PostV2DeploymentsInvokeMetadata(BaseModel):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""

    page_number: Nullable[float]
    r"""Page number of the chunk"""

    file_type: str
    r"""Type of the file"""

    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""

    rerank_score: Optional[float] = None
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["rerank_score"]
        nullable_fields = ["page_number"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2DeploymentsInvokeRetrievalsTypedDict(TypedDict):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""
    metadata: PostV2DeploymentsInvokeMetadataTypedDict
    r"""Metadata of the retrieved chunk from the knowledge base"""


class PostV2DeploymentsInvokeRetrievals(BaseModel):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""

    metadata: PostV2DeploymentsInvokeMetadata
    r"""Metadata of the retrieved chunk from the knowledge base"""


class DataTypedDict(TypedDict):
    id: NotRequired[str]
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""
    created: NotRequired[datetime]
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""
    object: NotRequired[PostV2DeploymentsInvokeObject]
    r"""Indicates the type of model used to generate the response"""
    model: NotRequired[str]
    r"""The model used to generate the response"""
    provider: NotRequired[PostV2DeploymentsInvokeProvider]
    r"""The provider used to generate the response"""
    is_final: NotRequired[bool]
    r"""Indicates if the response is the final response"""
    integration_id: NotRequired[str]
    r"""Indicates integration id used to generate the response"""
    finalized: NotRequired[datetime]
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""
    system_fingerprint: NotRequired[Nullable[str]]
    r"""Provider backed system fingerprint."""
    choices: NotRequired[List[PostV2DeploymentsInvokeDeploymentsChoicesTypedDict]]
    r"""A list of choices generated by the model"""
    retrievals: NotRequired[List[PostV2DeploymentsInvokeRetrievalsTypedDict]]
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""
    provider_response: NotRequired[Any]
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""


class Data(BaseModel):
    id: Optional[str] = None
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""

    created: Optional[datetime] = None
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""

    object: Optional[PostV2DeploymentsInvokeObject] = None
    r"""Indicates the type of model used to generate the response"""

    model: Optional[str] = None
    r"""The model used to generate the response"""

    provider: Optional[PostV2DeploymentsInvokeProvider] = None
    r"""The provider used to generate the response"""

    is_final: Optional[bool] = None
    r"""Indicates if the response is the final response"""

    integration_id: Optional[str] = None
    r"""Indicates integration id used to generate the response"""

    finalized: Optional[datetime] = None
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""

    system_fingerprint: OptionalNullable[str] = UNSET
    r"""Provider backed system fingerprint."""

    choices: Optional[List[PostV2DeploymentsInvokeDeploymentsChoices]] = None
    r"""A list of choices generated by the model"""

    retrievals: Optional[List[PostV2DeploymentsInvokeRetrievals]] = None
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""

    provider_response: Optional[Any] = None
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "id",
            "created",
            "object",
            "model",
            "provider",
            "is_final",
            "integration_id",
            "finalized",
            "system_fingerprint",
            "choices",
            "retrievals",
            "provider_response",
        ]
        nullable_fields = ["system_fingerprint"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2DeploymentsInvokeDeploymentsResponseBodyTypedDict(TypedDict):
    r"""Response from the gateway"""

    data: NotRequired[DataTypedDict]


class PostV2DeploymentsInvokeDeploymentsResponseBody(BaseModel):
    r"""Response from the gateway"""

    data: Optional[Data] = None


class Object(str, Enum):
    r"""Indicates the type of model used to generate the response"""

    CHAT = "chat"
    COMPLETION = "completion"
    IMAGE = "image"


class Provider(str, Enum):
    r"""The provider used to generate the response"""

    COHERE = "cohere"
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    HUGGINGFACE = "huggingface"
    REPLICATE = "replicate"
    GOOGLE = "google"
    GOOGLE_AI = "google-ai"
    AZURE = "azure"
    AWS = "aws"
    ANYSCALE = "anyscale"
    PERPLEXITY = "perplexity"
    GROQ = "groq"
    FAL = "fal"
    LEONARDOAI = "leonardoai"
    NVIDIA = "nvidia"


class PostV2DeploymentsInvokeMessageDeploymentsRole(str, Enum):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class Message3TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageDeploymentsRole
    r"""The role of the prompt message"""
    url: str


class Message3(BaseModel):
    role: PostV2DeploymentsInvokeMessageDeploymentsRole
    r"""The role of the prompt message"""

    url: str


class PostV2DeploymentsInvokeMessageRole(str, Enum):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class PostV2DeploymentsInvokeMessage2TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageRole
    r"""The role of the prompt message"""
    content: Nullable[str]


class PostV2DeploymentsInvokeMessage2(BaseModel):
    role: PostV2DeploymentsInvokeMessageRole
    r"""The role of the prompt message"""

    content: Nullable[str]

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = []
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class PostV2DeploymentsInvokeMessageDeploymentsResponseRole(str, Enum):
    r"""The role of the prompt message"""

    SYSTEM = "system"
    ASSISTANT = "assistant"
    USER = "user"
    EXCEPTION = "exception"
    TOOL = "tool"
    PROMPT = "prompt"
    CORRECTION = "correction"
    EXPECTED_OUTPUT = "expected_output"


class PostV2DeploymentsInvokeMessageType(str, Enum):
    FUNCTION = "function"


class PostV2DeploymentsInvokeMessageFunctionTypedDict(TypedDict):
    name: str
    arguments: str
    r"""JSON string arguments for the functions"""


class PostV2DeploymentsInvokeMessageFunction(BaseModel):
    name: str

    arguments: str
    r"""JSON string arguments for the functions"""


class PostV2DeploymentsInvokeMessageToolCallsTypedDict(TypedDict):
    type: PostV2DeploymentsInvokeMessageType
    function: PostV2DeploymentsInvokeMessageFunctionTypedDict
    id: NotRequired[str]
    index: NotRequired[float]


class PostV2DeploymentsInvokeMessageToolCalls(BaseModel):
    type: PostV2DeploymentsInvokeMessageType

    function: PostV2DeploymentsInvokeMessageFunction

    id: Optional[str] = None

    index: Optional[float] = None


class PostV2DeploymentsInvokeMessage1TypedDict(TypedDict):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponseRole
    r"""The role of the prompt message"""
    tool_calls: List[PostV2DeploymentsInvokeMessageToolCallsTypedDict]
    content: NotRequired[Nullable[str]]


class PostV2DeploymentsInvokeMessage1(BaseModel):
    role: PostV2DeploymentsInvokeMessageDeploymentsResponseRole
    r"""The role of the prompt message"""

    tool_calls: List[PostV2DeploymentsInvokeMessageToolCalls]

    content: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["content"]
        nullable_fields = ["content"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


PostV2DeploymentsInvokeMessageTypedDict = Union[
    PostV2DeploymentsInvokeMessage2TypedDict,
    Message3TypedDict,
    PostV2DeploymentsInvokeMessage1TypedDict,
]


PostV2DeploymentsInvokeMessage = Union[
    PostV2DeploymentsInvokeMessage2, Message3, PostV2DeploymentsInvokeMessage1
]


class PostV2DeploymentsInvokeChoicesTypedDict(TypedDict):
    index: float
    message: NotRequired[PostV2DeploymentsInvokeMessageTypedDict]
    finish_reason: NotRequired[Nullable[str]]


class PostV2DeploymentsInvokeChoices(BaseModel):
    index: float

    message: Optional[PostV2DeploymentsInvokeMessage] = None

    finish_reason: OptionalNullable[str] = UNSET

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["message", "finish_reason"]
        nullable_fields = ["finish_reason"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class MetadataTypedDict(TypedDict):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""
    page_number: Nullable[float]
    r"""Page number of the chunk"""
    file_type: str
    r"""Type of the file"""
    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""
    rerank_score: NotRequired[float]
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""


class Metadata(BaseModel):
    r"""Metadata of the retrieved chunk from the knowledge base"""

    file_name: str
    r"""Name of the file"""

    page_number: Nullable[float]
    r"""Page number of the chunk"""

    file_type: str
    r"""Type of the file"""

    search_score: float
    r"""Search scores are normalized to be in the range [0, 1]. Search score is calculated based on `[Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)` algorithm. Scores close to 1 indicate the document is closer to the query, and scores closer to 0 indicate the document is farther from the query."""

    rerank_score: Optional[float] = None
    r"""Rerank scores are normalized to be in the range [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to 0 indicate low relevance. It is not accurate to assume a score of 0.9 means the document is 2x more relevant than a document with a score of 0.45"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["rerank_score"]
        nullable_fields = ["page_number"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class RetrievalsTypedDict(TypedDict):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""
    metadata: MetadataTypedDict
    r"""Metadata of the retrieved chunk from the knowledge base"""


class Retrievals(BaseModel):
    document: str
    r"""Content of the retrieved chunk from the knowledge base"""

    metadata: Metadata
    r"""Metadata of the retrieved chunk from the knowledge base"""


class PostV2DeploymentsInvokeResponseBodyTypedDict(TypedDict):
    r"""Response from the gateway"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""
    created: datetime
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""
    object: Object
    r"""Indicates the type of model used to generate the response"""
    model: str
    r"""The model used to generate the response"""
    provider: Provider
    r"""The provider used to generate the response"""
    is_final: bool
    r"""Indicates if the response is the final response"""
    choices: List[PostV2DeploymentsInvokeChoicesTypedDict]
    r"""A list of choices generated by the model"""
    integration_id: NotRequired[str]
    r"""Indicates integration id used to generate the response"""
    finalized: NotRequired[datetime]
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""
    system_fingerprint: NotRequired[Nullable[str]]
    r"""Provider backed system fingerprint."""
    retrievals: NotRequired[List[RetrievalsTypedDict]]
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""
    provider_response: NotRequired[Any]
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""


class PostV2DeploymentsInvokeResponseBody(BaseModel):
    r"""Response from the gateway"""

    id: str
    r"""A unique identifier for the response. Can be used to add metrics to the transaction."""

    created: datetime
    r"""A timestamp indicating when the object was created. Usually in a standardized format like ISO 8601"""

    object: Object
    r"""Indicates the type of model used to generate the response"""

    model: str
    r"""The model used to generate the response"""

    provider: Provider
    r"""The provider used to generate the response"""

    is_final: bool
    r"""Indicates if the response is the final response"""

    choices: List[PostV2DeploymentsInvokeChoices]
    r"""A list of choices generated by the model"""

    integration_id: Optional[str] = None
    r"""Indicates integration id used to generate the response"""

    finalized: Optional[datetime] = None
    r"""A timestamp indicating when the object was finalized. Usually in a standardized format like ISO 8601"""

    system_fingerprint: OptionalNullable[str] = UNSET
    r"""Provider backed system fingerprint."""

    retrievals: Optional[List[Retrievals]] = None
    r"""List of documents retrieved from the knowledge base. This property is only available when the `include_retrievals` flag is set to `true` in the invoke settings. When stream is set to true, the `retrievals` property will be returned in the last streamed chunk where the property `is_final` is set to `true`."""

    provider_response: Optional[Any] = None
    r"""Response returned by the model provider. This functionality is only supported when streaming is not used. If streaming is used, the `provider_response` property will be set to `null`."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "integration_id",
            "finalized",
            "system_fingerprint",
            "retrievals",
            "provider_response",
        ]
        nullable_fields = ["system_fingerprint"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


PostV2DeploymentsInvokeResponseTypedDict = Union[
    PostV2DeploymentsInvokeResponseBodyTypedDict,
    Union[
        Generator[PostV2DeploymentsInvokeDeploymentsResponseBodyTypedDict, None, None],
        AsyncGenerator[PostV2DeploymentsInvokeDeploymentsResponseBodyTypedDict, None],
    ],
]


PostV2DeploymentsInvokeResponse = Union[
    PostV2DeploymentsInvokeResponseBody,
    Union[
        Generator[PostV2DeploymentsInvokeDeploymentsResponseBody, None, None],
        AsyncGenerator[PostV2DeploymentsInvokeDeploymentsResponseBody, None],
    ],
]
