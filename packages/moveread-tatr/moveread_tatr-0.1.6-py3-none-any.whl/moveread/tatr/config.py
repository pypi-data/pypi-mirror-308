from transformers import TableTransformerConfig

config = TableTransformerConfig(
  activation_dropout=0.0,
  activation_function="relu",
  architectures=["TableTransformerForObjectDetection"],
  attention_dropout=0.0,
  auxiliary_loss=False,
  use_pretrained_backbone=False,
  backbone_config={
    "add_cross_attention": False,
    "architectures": ["ResNetForImageClassification"],
    "bad_words_ids": None,
    "begin_suppress_tokens": None,
    "bos_token_id": None,
    "chunk_size_feed_forward": 0,
    "cross_attention_hidden_size": None,
    "decoder_start_token_id": None,
    "depths": [2, 2, 2, 2],
    "diversity_penalty": 0.0,
    "do_sample": False,
    "downsample_in_bottleneck": False,
    "downsample_in_first_stage": False,
    "early_stopping": False,
    "embedding_size": 64,
    "encoder_no_repeat_ngram_size": 0,
    "eos_token_id": None,
    "exponential_decay_length_penalty": None,
    "finetuning_task": None,
    "forced_bos_token_id": None,
    "forced_eos_token_id": None,
    "hidden_act": "relu",
    "hidden_sizes": [64, 128, 256, 512],
    "layer_type": "basic",
    "length_penalty": 1.0,
    "max_length": 20,
    "min_length": 0,
    "model_type": "resnet",
    "no_repeat_ngram_size": 0,
    "num_beam_groups": 1,
    "num_beams": 1,
    "num_channels": 3,
    "num_return_sequences": 1,
    "out_features": ["stage1", "stage2", "stage3", "stage4"],
    "out_indices": [1, 2, 3, 4],
    "output_attentions": False,
    "output_hidden_states": False,
    "output_scores": False,
    "pad_token_id": None,
    "prefix": None,
    "problem_type": None,
    "pruned_heads": {},
    "remove_invalid_values": False,
    "repetition_penalty": 1.0,
    "return_dict": True,
    "return_dict_in_generate": False,
    "sep_token_id": None,
    "stage_names": ["stem", "stage1", "stage2", "stage3", "stage4"],
    "suppress_tokens": None,
    "task_specific_params": None,
    "temperature": 1.0,
    "tf_legacy_loss": False,
    "tie_encoder_decoder": False,
    "tie_word_embeddings": True,
    "tokenizer_class": None,
    "top_k": 50,
    "top_p": 1.0,
    "torch_dtype": "float32",
    "torchscript": False,
    "typical_p": 1.0,
    "use_bfloat16": False,
  },
  backbone_kwargs=None,
  bbox_cost=5,
  bbox_loss_coefficient=5,
  ce_loss_coefficient=1,
  class_cost=1,
  d_model=256,
  decoder_attention_heads=8,
  decoder_ffn_dim=2048,
  decoder_layerdrop=0.0,
  decoder_layers=6,
  dice_loss_coefficient=1,
  dropout=0.1,
  encoder_attention_heads=8,
  encoder_ffn_dim=2048,
  encoder_layerdrop=0.0,
  encoder_layers=6,
  eos_coefficient=0.4,
  giou_cost=2,
  giou_loss_coefficient=2,
  id2label={
    0: "cell",
    1: "pair",
    2: "block",
    3: "grid"
  },
  init_std=0.02,
  init_xavier_std=1.0,
  is_encoder_decoder=True,
  label2id={
    "table": 0,
    "table column": 1,
    "table column header": 3,
    "table projected row header": 4,
    "table row": 2,
    "table spanning cell": 5,
  },
  mask_loss_coefficient=1,
  model_type="table-transformer",
  num_channels=3,
  num_hidden_layers=6,
  num_queries=250,
  position_embedding_type="sine",
  torch_dtype="float32",
  transformers_version="4.44.0",
  use_timm_backbone=False
)
